{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Permutation Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple example. Consider the average course grades for EEE 5544 over the past 6 years, omitting 2017 (when I didn't teach it):\n",
    "\n",
    "|Year | Grade|\n",
    "|-|-|\n",
    "|2013|74.1|\n",
    "|2014|74.5|\n",
    "|2015|79.4|\n",
    "|2016|79.0|\n",
    "|2018|78.4|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the means for the first 2013-2014 vs 2015-2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades1=np.array([74.1,74.5])\n",
    "grades2=np.array([79.4,79,78.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74.3, 78.93333333333334)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades1.mean(), grades2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.63333333333334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff= grades2.mean()- grades1.mean()\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the average grade increased over time, or could this just be attributable to the small number of samples?\n",
    "\n",
    "We could perform bootstrap resampling under the null hypothesis, but the data is so small, we might get repeats of the same samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to pool the data and try **all** the ways to rsample the data into samples of size 2 and 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Permutation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Fisher's exact permutation test (for binary hypothesis testing), we:\n",
    "\n",
    "1. Pool the data\n",
    "2. Find every partition of the data into two subsets (with sizes equal to the original samples)\n",
    "3. Measure the sample statistics for each new sample\n",
    "4. Determine whether the new sample statistics are as extreme as the original observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we demonstrate how to find all the subsets of a certain size for a list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.combinations at 0x11a106c28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itertools.combinations([1,2,3,4,5,6],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3),\n",
       " (1, 2, 4),\n",
       " (1, 2, 5),\n",
       " (1, 2, 6),\n",
       " (1, 3, 4),\n",
       " (1, 3, 5),\n",
       " (1, 3, 6),\n",
       " (1, 4, 5),\n",
       " (1, 4, 6),\n",
       " (1, 5, 6),\n",
       " (2, 3, 4),\n",
       " (2, 3, 5),\n",
       " (2, 3, 6),\n",
       " (2, 4, 5),\n",
       " (2, 4, 6),\n",
       " (2, 5, 6),\n",
       " (3, 4, 5),\n",
       " (3, 4, 6),\n",
       " (3, 5, 6),\n",
       " (4, 5, 6)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples=list(itertools.combinations([1,2,3,4,5,6],3))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom(6,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can pull all the samples of size 2 from our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74.1, 74.5, 79.4, 79. , 78.4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled=np.hstack((grades1,grades2))\n",
    "pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(74.1, 74.5),\n",
       " (74.1, 79.4),\n",
       " (74.1, 79.0),\n",
       " (74.1, 78.4),\n",
       " (74.5, 79.4),\n",
       " (74.5, 79.0),\n",
       " (74.5, 78.4),\n",
       " (79.4, 79.0),\n",
       " (79.4, 78.4),\n",
       " (79.0, 78.4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples1=list(itertools.combinations(pooled,2))\n",
    "samples1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick is that for each sample, we need to find the remaining set to go in the other sample.  We can use numpy's ```setxor1d``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74.1, 74.5), array([78.4, 79. , 79.4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples1[0],np.setxor1d(pooled,samples1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74.1, 74.5) [78.4 79.  79.4]\n",
      "(74.1, 79.4) [74.5 78.4 79. ]\n",
      "(74.1, 79.0) [74.5 78.4 79.4]\n",
      "(74.1, 78.4) [74.5 79.  79.4]\n",
      "(74.5, 79.4) [74.1 78.4 79. ]\n",
      "(74.5, 79.0) [74.1 78.4 79.4]\n",
      "(74.5, 78.4) [74.1 79.  79.4]\n",
      "(79.4, 79.0) [74.1 74.5 78.4]\n",
      "(79.4, 78.4) [74.1 74.5 79. ]\n",
      "(79.0, 78.4) [74.1 74.5 79.4]\n"
     ]
    }
   ],
   "source": [
    "for samples1 in itertools.combinations(pooled,2):\n",
    "    samples2= np.setxor1d(pooled,samples1)\n",
    "    print(samples1,samples2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to conduct our exact permutation test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. that mean difference is >= 4.63333333333334 =~ 0.0\n"
     ]
    }
   ],
   "source": [
    "perm_count = 0\n",
    "event_count = 0\n",
    "for samples1 in itertools.combinations(pooled,2):\n",
    "    samples2= np.setxor1d(pooled,samples1)\n",
    "    mean1 = np.mean(samples1)\n",
    "    mean2 = np.mean(samples1)\n",
    "    sample_diff = mean2-mean1\n",
    "    perm_count+=1\n",
    "    if abs(sample_diff) >= diff:\n",
    "        event_count+=1\n",
    "        \n",
    "print(\"Prob. that mean difference is >=\", diff, \"=~\", event_count/perm_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not enough data to support that the average score has increased in the last 3 years of the study. \n",
    "\n",
    "(Since there are only 10 permutations, we can never get a $p$-value less than 0.1 with data sets of 2 values and 3 values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike resampling, this approach tries **every** way or redistributing the pooled data. So why not always use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the previous example, where the data for the 50 states were split into two clusters of size 42 and 8. How many different combinations of samples would be created in the exact permutation test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536878650.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom(50,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536878650.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom(50,42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how can we handle a case like this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Permutation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the following question that should be of interest to engineers: Do males score higher on standardized high school math and science tests than females?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data from the \"High School & Beyond (HS&B)\" survey conducted y the National Center for Education Statistics:\n",
    "\n",
    "https://nces.ed.gov/surveys/hsb/index.asp\n",
    "\n",
    "We are using a CSV file with 200 randomly selected observations from that data set. The CSV file is available here:\n",
    "\n",
    "https://github.com/rpruim/OpenIntro/blob/master/data/hsb2.csv\n",
    "\n",
    "A brief discussion of the different fields is available at\n",
    "\n",
    "http://www.philender.com/courses/762/notes1/about_hsb2.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"hsb2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to partition this dataframes into two seperate dataframes according to gender. This is easy to do in pandas, but it looks a little strange. First we get a boolean Series that contains True for whichever rows we want to keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"]==\"male\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we pass that Series as indices to the original dataframe, it will return a new dataframe with only those rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "males=df[df[\"gender\"]==\"male\"]\n",
    "males;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "females=df[df[\"gender\"]==\"female\"]\n",
    "females;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with math scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., 10., 15., 12., 16., 22., 10., 10.,  7.,  6.]),\n",
       " array([33. , 36.9, 40.8, 44.7, 48.6, 52.5, 56.4, 60.3, 64.2, 68.1, 72. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(males[\"math\"])\n",
    "plt.hist(females[\"math\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  2.,  8.,  9.,  6.,  8.,  4.,  9.,  7., 12., 10.,  7.,  3.,\n",
       "         5.,  5.,  5.,  2.,  2.,  4.,  0.]),\n",
       " array([35., 37., 39., 41., 43., 45., 47., 49., 51., 53., 55., 57., 59.,\n",
       "        61., 63., 65., 67., 69., 71., 73., 75.]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts,my_bins,_ = plt.hist(males[\"math\"], bins=20, alpha=0.5)\n",
    "plt.hist(females[\"math\"], bins = my_bins, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52.94505494505494, 52.39449541284404)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(males[\"math\"]),np.mean(females[\"math\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you infer from this plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to guess that this is probably not statistically significant, we can test more later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider science scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.00382263, 0.00764526, 0.01529052, 0.00382263,\n",
       "        0.03058104, 0.03058104, 0.03058104, 0.02675841, 0.00764526,\n",
       "        0.06498471, 0.04204893, 0.04204893, 0.04204893, 0.02675841,\n",
       "        0.01529052, 0.01146789, 0.01529052, 0.        , 0.        ]),\n",
       " array([26. , 28.4, 30.8, 33.2, 35.6, 38. , 40.4, 42.8, 45.2, 47.6, 50. ,\n",
       "        52.4, 54.8, 57.2, 59.6, 62. , 64.4, 66.8, 69.2, 71.6, 74. ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts,my_bins,_ = plt.hist(males[\"science\"], bins=20, alpha=0.5, density=True)\n",
    "plt.hist(females[\"science\"], bins = my_bins, alpha=0.5, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53.23076923076923, 50.69724770642202)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(males[\"science\"]),np.mean(females[\"science\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.533521524347215"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.mean(males[\"science\"]) - np.mean(females[\"science\"])\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this result statistically significant? \n",
    "\n",
    "How many different sample combinations are there in the exact permutation test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.040047748665152e+58"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom(200,91)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, let's sample 10,000 of the permutations. Since there are so many, we will randomly select permutations, so there is some small probability of repeat\n",
    "\n",
    "To choose the samples, we will permute the pooled data and then subdivide into the appropriate sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = df[\"science\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of seeing mean diff >= 2.533521524347215 under H0 is =~ 0.07193\n"
     ]
    }
   ],
   "source": [
    "diff = np.mean(males[\"science\"]) - np.mean(females[\"science\"])\n",
    "pooled = df[\"science\"]\n",
    "num_sims = 100000\n",
    "event_count = 0\n",
    "\n",
    "for sim in range(num_sims):\n",
    "    perm = npr.permutation(pooled)\n",
    "    # first 91 and last 109\n",
    "    male_sample = perm[:len(males)]\n",
    "    female_sample = perm[len(males):]\n",
    "    sample_diff = male_sample.mean()-female_sample.mean()\n",
    "    if abs(sample_diff) >= diff:\n",
    "        event_count+=1\n",
    "        \n",
    "monte_p_val = event_count/num_sims\n",
    "\n",
    "print(\"Prob. of seeing mean diff >=\", diff,\"under H0 is =~\", monte_p_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not statistically significant at the p < 0.01 level. We cannot be sure that the observed mean difference is caused by a true difference in the underlying populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read     --\t Males: 52.824175824175825 \tFemales: 51.73394495412844\n",
      "write    --\t Males: 50.120879120879124 \tFemales: 54.99082568807339\n",
      "math     --\t Males: 52.94505494505494 \tFemales: 52.39449541284404\n",
      "science  --\t Males: 53.23076923076923 \tFemales: 50.69724770642202\n",
      "socst    --\t Males: 51.79120879120879 \tFemales: 52.91743119266055\n"
     ]
    }
   ],
   "source": [
    "# Here are all the average values\n",
    "tests=[\"read\",\"write\",\"math\",\"science\",\"socst\"]\n",
    "for test in tests:\n",
    "    print(test.ljust(8),\"--\\t\", \"Males:\",males[test].mean(),\"\\tFemales:\",females[test].mean())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Defn:\n",
    "    A collection of events A1,A2,...,An partitions the sample space (s) iff:\n",
    "        1) Ai intersection Aj = null, for all i,j in {1,2,...,N}\n",
    "        2) The union of each event together = S\n",
    "            the events make a \"tiling\" of S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lecture 13 Assignment**\n",
    "\n",
    "1. Conduct a bootstrap resampling test for statistical significance of the difference in average science scores between the genders. Compare the $p$-value for the bootstrap test vs. that found via the Monte Carlo permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under null hypothesis, observe effect this large with prob. 0.07024.\n",
      "The ùëù-value for the bootstrap test is 0.07024, as shown above and the ùëù-value found via the Monte Carlo Permutation test is 0.07193. As you can see, there is very little difference between them and either technique works well for this data.\n"
     ]
    }
   ],
   "source": [
    "diff = np.mean(males[\"science\"]) - np.mean(females[\"science\"])\n",
    "pooled = df[\"science\"]\n",
    "num_sims=100000\n",
    "event_count=0\n",
    "for sim in range(num_sims):\n",
    "    sample_males=npr.choice(pooled,len(males))\n",
    "    sample_females=npr.choice(pooled,len(females))\n",
    "    sample_diff =sample_males.mean()-sample_females.mean()\n",
    "    if abs(sample_diff) >= diff:\n",
    "        event_count+=1\n",
    "\n",
    "bootstrap_p_val = event_count/num_sims\n",
    "\n",
    "print(\"Under null hypothesis, observe effect this large with prob. \",bootstrap_p_val, \".\", sep=\"\")\n",
    "print(\"The ùëù-value for the bootstrap test is \",bootstrap_p_val,\", as shown above and the ùëù-value found via the Monte Carlo Permutation test is \",monte_p_val,\". As you can see, there is very little difference between them and either technique works well for this data.\",sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generate a table of the median values for all tests, by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\tread\twrite\tmath\tscience\n",
      "males\t52.0\t52.0\t52.0\t55.0\t\n",
      "females\t50.0\t57.0\t53.0\t50.0\t\n"
     ]
    }
   ],
   "source": [
    "females=df[df[\"gender\"]==\"female\"]\n",
    "males=df[df[\"gender\"]==\"male\"]\n",
    "tests = [\"read\", \"write\", \"math\", \"science\"]\n",
    "genders = [males, females]\n",
    "\n",
    "print(\"gender\\tread\\twrite\\tmath\\tscience\",sep=\"\")\n",
    "for i in range(0,len(genders)):\n",
    "    gender = \"males\" if i==0 else \"females\"\n",
    "    print(gender,\"\\t\",sep=\"\",end=\"\")\n",
    "    for test in tests:\n",
    "        print(np.median(genders[i][test]),\"\\t\",sep=\"\",end=\"\")\n",
    "    print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the median writing score for men vs women? Using a Monte Carlo permutation test (not bootstrap resampling), answer the following questions. Is the difference statistically significant at the p<0.01 level? What is the 99% confidence interval for the difference in medians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median writing score for men vs. women is 52.0 vs. 57.0, with a median difference of -5.0.\n",
      "Prob. of seeing median diff >= 5.0 under H0 is = ~0.075.\n",
      "The difference is NOT statistically significant at the p < 0.01 level.\n",
      "The 99% confidence interval is [-5.0, 5.0].\n"
     ]
    }
   ],
   "source": [
    "np.median(females[\"write\"])\n",
    "median_diff = np.median(males[\"write\"]) - np.median(females[\"write\"])\n",
    "print(\"The median writing score for men vs. women is \",np.median(males[\"write\"]),\" vs. \", np.median(females[\"write\"]),\", with a median difference of \", median_diff,\".\", sep=\"\")\n",
    "pooled = df[\"write\"]\n",
    "num_sims = 10000\n",
    "bs_stats=[]\n",
    "event_count = 0\n",
    "for sim in range(num_sims):\n",
    "    perm = npr.permutation(pooled)\n",
    "    # first 91 and last 109\n",
    "    male_sample = perm[:len(males)]\n",
    "    female_sample = perm[len(males):]\n",
    "    sample_diff = np.median(male_sample)-np.median(female_sample)\n",
    "    bs_stats+=[sample_diff]\n",
    "#     print(sample_diff,end=\" \")\n",
    "    if sample_diff**2 >= median_diff**2:\n",
    "        event_count+=1\n",
    "        \n",
    "print(\"Prob. of seeing median diff >= \", abs(median_diff),\" under H0 is = ~\", event_count/num_sims,\".\", sep=\"\")\n",
    "print(\"The difference is NOT statistically significant at the p < 0.01 level.\")\n",
    "\n",
    "# calculate 99% confidence interval\n",
    "bs_stats.sort()\n",
    "lower=int(len(bs_stats)*0.01/2)\n",
    "upper=int(len(bs_stats)-lower-1)\n",
    "bs_stats[lower],bs_stats[upper]\n",
    "print('The 99% confidence interval is [',bs_stats[lower],', ',bs_stats[upper],'].',sep=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
